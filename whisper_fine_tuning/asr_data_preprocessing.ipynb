{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce1a1ed-e520-46dd-a971-d26485d4f564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import pickle\n",
    "import shutil\n",
    "import librosa\n",
    "import subprocess\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01585cf-5718-4d7a-9c56-acfbd78a61a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_length_audios = []\n",
    "\n",
    "def khosapogh_data_preprocessing(root_dir, output_dir):\n",
    "    data_dict = {}\n",
    "    root_files = os.listdir(root_dir)\n",
    "    path = root_dir + \"/\"\n",
    "    joining_number = 0\n",
    "    for file in root_files:\n",
    "        \n",
    "        if file.endswith(\".txt\"):\n",
    "            sentence = \"\"\n",
    "            with open(path + file, 'r') as f:\n",
    "                file_contents = f.read()\n",
    "            lines = file_contents.split('\\n')\n",
    "            for line in lines:\n",
    "                sentence += \" \" + line\n",
    "            data_dict[str(joining_number)] = sentence\n",
    "            \n",
    "            for file_ in root_files:\n",
    "                if file_.endswith(\".wav\") and file_.split(\".\")[0] == file.split(\".\")[0]:\n",
    "                    \n",
    "                    input_file = path + file_\n",
    "                    output_file = os.path.join(output_dir, str(joining_number)+\".wav\")\n",
    "                    \n",
    "                    try:\n",
    "                        y, sr = librosa.load(input_file, sr=None)\n",
    "                        if sr != 16000:\n",
    "                            y_resampled = librosa.resample(y, orig_sr=sr, target_sr=16000)\n",
    "                            sf.write(output_file, y_resampled, 16000, 'PCM_16')\n",
    "                        else:\n",
    "                            shutil.copy(input_file, output_file)\n",
    "                    except:\n",
    "                        \n",
    "                        sampling_rate = 16000  \n",
    "                        ffmpeg_command = [\n",
    "                            'ffmpeg',                     \n",
    "                            '-i', input_file,              \n",
    "                            '-c:a', 'pcm_s16le',           \n",
    "                            '-ar', str(sampling_rate),  \n",
    "                            output_file                    \n",
    "                        ]\n",
    "                        \n",
    "                        #problematic audio detection\n",
    "                        subprocess.run(ffmpeg_command)\n",
    "                        file = tf.io.read_file(output_file)\n",
    "                        audio, _ = tf.audio.decode_wav(file)\n",
    "                        if len(audio.numpy()) == 0:\n",
    "                            zero_length_audios.append([path + file_,output_file])\n",
    "\n",
    "                    \n",
    "                    \n",
    "            joining_number+=1\n",
    "            \n",
    "    with open('arm_sentences.pkl', 'wb') as f:\n",
    "        pickle.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60a5678-ce2b-4d1f-99f8-a59658e1888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_output_directory = 'Renamed_Audio_Recordings'\n",
    "khosapogh_data_directory = \"dataset_new_verified\"\n",
    "khosapogh_data_preprocessing(khosapogh_data_directory, audio_output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a47bce-5123-408f-8884-b7ad1bfea6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('arm_sentences.pkl', 'rb') as f:\n",
    "    sentences_dict = pickle.load(f)\n",
    "sentences_dict \n",
    "\n",
    "len(sentences_dict), len(os.listdir(audio_output_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94197f0e-0c6b-4943-ae02-ddcc99c65f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def armenian_sentence_processing(sentence):\n",
    "    arm_range = range(ord(\"ա\"), ord(\"և\") + 1)\n",
    "    allowed_punctuations = set([\"։\", \",\", \" \"])\n",
    "    sentence = sentence.lower()\n",
    "    sentence = sentence.strip()\n",
    "    sentence = sentence.replace(\":\", \"։\")\n",
    "    sentence = \"\".join([char for char in sentence if (ord(char) in arm_range or char in allowed_punctuations)])\n",
    "    if sentence[-1] == \"։\":\n",
    "        sentence = sentence[:-1]\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a642dc1f-64b2-4f05-be22-31a3f7e7b8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm.tqdm(range(len(sentences_dict))):\n",
    "    sentences_dict[str(i)] = armenian_sentence_processing(sentences_dict[str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849f2557-3fa8-4808-919e-080042461487",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('arm_sentences.pkl', 'wb') as f:\n",
    "    pickle.dump(sentences_dict, f)\n",
    "    \n",
    "with open('arm_sentences.pkl', 'rb') as f:\n",
    "    sentences_dict = pickle.load(f)\n",
    "sentences_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d187032-2d4e-4b68-bd91-0f5a1389c2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wav_dir = 'wavs_final'\n",
    "\n",
    "def resample_wav(input_file, output_file, target_sr=16000):\n",
    "    y, sr = librosa.load(input_file, sr=None)\n",
    "    y_resampled = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n",
    "    sf.write(output_file, y_resampled, target_sr)\n",
    "\n",
    "\n",
    "\n",
    "for filename in tqdm.tqdm(os.listdir(audio_output_directory)):\n",
    "    if filename.endswith('.wav'):\n",
    "        input_file = os.path.join(audio_output_directory, filename)\n",
    "        output_file = os.path.join(new_wav_dir, filename)\n",
    "        resample_wav(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccff9b01-7dcb-45c1-8c20-f1b704f9c8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'metadata.csv'\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"file_name\", \"normalized_transcription\"])\n",
    "    for key, value in sentences_dict.items():\n",
    "        writer.writerow([key, value])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
